<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>SGA - Graph Sampling for Neural Relational Inference – Deep Learning/NLP course</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../../">
<script src="../../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../../../index.html">
    <span class="navbar-title">Deep Learning/NLP course</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../dl.html"> 
<span class="menu-text">Deep Learning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../nlp.html"> 
<span class="menu-text">Natural Language Processing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#graph-network-encoder" id="toc-graph-network-encoder" class="nav-link active" data-scroll-target="#graph-network-encoder">Graph Network Encoder</a></li>
  <li><a href="#graph-network-decoder" id="toc-graph-network-decoder" class="nav-link" data-scroll-target="#graph-network-decoder">Graph Network Decoder</a></li>
  <li><a href="#neural-relational-inference" id="toc-neural-relational-inference" class="nav-link" data-scroll-target="#neural-relational-inference">Neural Relational Inference</a>
  <ul class="collapse">
  <li><a href="#loading-and-exmaining-data" id="toc-loading-and-exmaining-data" class="nav-link" data-scroll-target="#loading-and-exmaining-data">Loading and Exmaining Data</a></li>
  <li><a href="#encoder" id="toc-encoder" class="nav-link" data-scroll-target="#encoder">Encoder</a></li>
  <li><a href="#decoder" id="toc-decoder" class="nav-link" data-scroll-target="#decoder">Decoder</a></li>
  <li><a href="#discrete-sampling" id="toc-discrete-sampling" class="nav-link" data-scroll-target="#discrete-sampling">Discrete Sampling</a></li>
  <li><a href="#visualizing-discovered-graphs" id="toc-visualizing-discovered-graphs" class="nav-link" data-scroll-target="#visualizing-discovered-graphs">Visualizing Discovered Graphs</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">SGA - Graph Sampling for Neural Relational Inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Notebook:</strong> <a href="https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/sampling/graphs.ipynb"><img src="https://img.shields.io/static/v1.svg?logo=github&amp;label=Repo&amp;message=View%20On%20Github&amp;color=lightgrey" class="img-fluid" alt="View on Github"></a> <a href="https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/sampling/graphs.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Collab"></a><br>
<strong>Author:</strong> Adeel Pervez</p>
<p>In this tutorials we show an example of a variational autoencoder model with graph structured latent spaces. This model is called Neural Relational Inference and is described in this <a href="https://arxiv.org/abs/1802.04687">paper</a>. This tutorial uses code from the associated code base available <a href="https://github.com/ethanfetaya/NRI">here</a></p>
<p>The problem dealt by this model is one of predicting particle trajectories. Suppose that we have <span class="math inline">\(N\)</span> interacting particles (say, charges) with some interaction structure (say, attractive/repulsive forces) that are moving about in space. For each particle we are observe its trajectory (say, position and velocity) as it moves about over some period of time T. Each new state in the trajectory of a particle will depend on the current state (position and velocity) and on the interaction with other particles. Our data consists of a set of <span class="math inline">\(N\)</span> particle trajectories but the actual interactions are unknown. The task of our model is to learn the dynamics of the particles to predict future trajectories given example trajectories only.</p>
<p>Notice that the task of predicting particle dynamics would become easier if we knew the form of the interactions between particles. which we think of as a graph of interactions. Each particle in the system would occupy a node in the graph and the strength of the interaction could be represented by the weight of the graph. The interaction graph could be fed to a neural network along with the currently known trajectory which could then predict the next steps of the particles.</p>
<p>However, since in this problem we are not given the interaction graph, the approach taken by Neural Relational Inference is to use the encoder of a variational autoencoder to sample a graph using the given trajectory as input. For this the method uses a graph neural network as encoder.</p>
<section id="graph-network-encoder" class="level2">
<h2 class="anchored" data-anchor-id="graph-network-encoder">Graph Network Encoder</h2>
<p>Since graph neural networks already require a graph over which to pass messages, the encoder starts with a fully connected graph with each node representing a particle. The entire trajectory information for a particle is used as the input feature for each node. Node features are transformed and passed over edges and concatenated to form edge features. This process can be repeated to get a deeper network with edge features as the output.</p>
<p>The edge features are then transformed into edge weights (as (unnormalized) log probabilities). Finally from these edge weights we can sample an interaction graph by sample edges according to their weights. This interaction graph then serves as a latent variable <span class="math inline">\(z\)</span> to be used in the decoder where <span class="math inline">\(z_{ij}\)</span> indicates whether edge <span class="math inline">\((i,j)\)</span> is present in the graph. Since we need to backpropagate into the encoder we relax the edge sampling operation using the Gumbel-Softmax relaxation.</p>
</section>
<section id="graph-network-decoder" class="level2">
<h2 class="anchored" data-anchor-id="graph-network-decoder">Graph Network Decoder</h2>
<p>In the decoder we use another graph network which uses the graph sampled by the encoder and the input trajectory to predict the next step in the trajectory for some predefined number of steps. The models uses a gaussian likelihood loss for the trajectory which is fed into the VAE loss for optimization.</p>
<p>The model structure can be seen in the following figure from the paper linked above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/nri.png" class="img-fluid figure-img"></p>
<figcaption>nri</figcaption>
</figure>
</div>
</section>
<section id="neural-relational-inference" class="level2">
<h2 class="anchored" data-anchor-id="neural-relational-inference">Neural Relational Inference</h2>
<p>Now we build a model to learn the dynamics of a 5 particle system connected by springs. The trajectory data for this system has been generated synthetically using the dynamical equations of motion and a ground truth interaction graph. The code to load the data is given in the <code>load_data</code> function in <code>utils.py</code>.</p>
<p>As the first step we begin with downloading loading the data.</p>
<div id="f64c021a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">-</span>O <span class="st">'nri_springs.zip'</span> https:<span class="op">//</span>surfdrive.surf.nl<span class="op">/</span>files<span class="op">/</span>index.php<span class="op">/</span>s<span class="op">/</span>LXV9iJjxfu5jhdD<span class="op">/</span>download</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--2022-06-21 17:04:34--  https://surfdrive.surf.nl/files/index.php/s/LXV9iJjxfu5jhdD/download
Resolving surfdrive.surf.nl (surfdrive.surf.nl)... 145.100.27.67, 2001:610:108:203b:0:a11:da7a:5afe
Connecting to surfdrive.surf.nl (surfdrive.surf.nl)|145.100.27.67|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 586393709 (559M) [application/zip]
Saving to: ‘nri_springs.zip’

100%[======================================&gt;] 586,393,709 21.9MB/s   in 21s    

2022-06-21 17:04:55 (26.1 MB/s) - ‘nri_springs.zip’ saved [586393709/586393709]
</code></pre>
</div>
</div>
<div id="b953f7a0" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>u nri_springs.<span class="bu">zip</span> <span class="op">-</span>d data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Archive:  nri_springs.zip</code></pre>
</div>
</div>
<div id="7bf5d23c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> argparse</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#import math</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data.dataset <span class="im">import</span> TensorDataset</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.autograd <span class="im">import</span> Variable</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> lr_scheduler</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> networkx</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ModuleNotFoundError</span>: </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>pip install <span class="op">--</span>quiet networkx</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> networkx</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="loading-and-exmaining-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-and-exmaining-data">Loading and Exmaining Data</h3>
<p>Next we load the data, convert the arrays into torch tensors and return the loader objects.</p>
<div id="7eca925a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(batch_size<span class="op">=</span><span class="dv">1</span>, suffix<span class="op">=</span><span class="st">''</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    loc_train <span class="op">=</span> np.load(<span class="st">'data/loc_train'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    vel_train <span class="op">=</span> np.load(<span class="st">'data/vel_train'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    edges_train <span class="op">=</span> np.load(<span class="st">'data/edges_train'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    loc_valid <span class="op">=</span> np.load(<span class="st">'data/loc_valid'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    vel_valid <span class="op">=</span> np.load(<span class="st">'data/vel_valid'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    edges_valid <span class="op">=</span> np.load(<span class="st">'data/edges_valid'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    loc_test <span class="op">=</span> np.load(<span class="st">'data/loc_test'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    vel_test <span class="op">=</span> np.load(<span class="st">'data/vel_test'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    edges_test <span class="op">=</span> np.load(<span class="st">'data/edges_test'</span> <span class="op">+</span> suffix <span class="op">+</span> <span class="st">'.npy'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [num_samples, num_timesteps, num_dims, num_atoms]</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    num_atoms <span class="op">=</span> loc_train.shape[<span class="dv">3</span>]</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    loc_max <span class="op">=</span> loc_train.<span class="bu">max</span>()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    loc_min <span class="op">=</span> loc_train.<span class="bu">min</span>()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    vel_max <span class="op">=</span> vel_train.<span class="bu">max</span>()</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    vel_min <span class="op">=</span> vel_train.<span class="bu">min</span>()</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize to [-1, 1]</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    loc_train <span class="op">=</span> (loc_train <span class="op">-</span> loc_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (loc_max <span class="op">-</span> loc_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    vel_train <span class="op">=</span> (vel_train <span class="op">-</span> vel_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (vel_max <span class="op">-</span> vel_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    loc_valid <span class="op">=</span> (loc_valid <span class="op">-</span> loc_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (loc_max <span class="op">-</span> loc_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    vel_valid <span class="op">=</span> (vel_valid <span class="op">-</span> vel_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (vel_max <span class="op">-</span> vel_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    loc_test <span class="op">=</span> (loc_test <span class="op">-</span> loc_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (loc_max <span class="op">-</span> loc_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    vel_test <span class="op">=</span> (vel_test <span class="op">-</span> vel_min) <span class="op">*</span> <span class="dv">2</span> <span class="op">/</span> (vel_max <span class="op">-</span> vel_min) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    loc_train <span class="op">=</span> np.transpose(loc_train, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    vel_train <span class="op">=</span> np.transpose(vel_train, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    feat_train <span class="op">=</span> np.concatenate([loc_train, vel_train], axis<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    edges_train <span class="op">=</span> np.reshape(edges_train, [<span class="op">-</span><span class="dv">1</span>, num_atoms <span class="op">**</span> <span class="dv">2</span>])</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    edges_train <span class="op">=</span> np.array((edges_train <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span>, dtype<span class="op">=</span>np.int64)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    loc_valid <span class="op">=</span> np.transpose(loc_valid, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    vel_valid <span class="op">=</span> np.transpose(vel_valid, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    feat_valid <span class="op">=</span> np.concatenate([loc_valid, vel_valid], axis<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    edges_valid <span class="op">=</span> np.reshape(edges_valid, [<span class="op">-</span><span class="dv">1</span>, num_atoms <span class="op">**</span> <span class="dv">2</span>])</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    edges_valid <span class="op">=</span> np.array((edges_valid <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span>, dtype<span class="op">=</span>np.int64)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    loc_test <span class="op">=</span> np.transpose(loc_test, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    vel_test <span class="op">=</span> np.transpose(vel_test, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    feat_test <span class="op">=</span> np.concatenate([loc_test, vel_test], axis<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    edges_test <span class="op">=</span> np.reshape(edges_test, [<span class="op">-</span><span class="dv">1</span>, num_atoms <span class="op">**</span> <span class="dv">2</span>])</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    edges_test <span class="op">=</span> np.array((edges_test <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span>, dtype<span class="op">=</span>np.int64)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    feat_train <span class="op">=</span> torch.FloatTensor(feat_train)</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    edges_train <span class="op">=</span> torch.LongTensor(edges_train)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    feat_valid <span class="op">=</span> torch.FloatTensor(feat_valid)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    edges_valid <span class="op">=</span> torch.LongTensor(edges_valid)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    feat_test <span class="op">=</span> torch.FloatTensor(feat_test)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    edges_test <span class="op">=</span> torch.LongTensor(edges_test)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Exclude self edges</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>    off_diag_idx <span class="op">=</span> np.ravel_multi_index(</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>        np.where(np.ones((num_atoms, num_atoms)) <span class="op">-</span> np.eye(num_atoms)),</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>        [num_atoms, num_atoms])</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>    edges_train <span class="op">=</span> edges_train[:, off_diag_idx]</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    edges_valid <span class="op">=</span> edges_valid[:, off_diag_idx]</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>    edges_test <span class="op">=</span> edges_test[:, off_diag_idx]</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> TensorDataset(feat_train, edges_train)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    valid_data <span class="op">=</span> TensorDataset(feat_valid, edges_valid)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> TensorDataset(feat_test, edges_test)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    train_data_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    valid_data_loader <span class="op">=</span> DataLoader(valid_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>    test_data_loader <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_data_loader, valid_data_loader, test_data_loader, loc_max, loc_min, vel_max, vel_min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We specify the batch size and the data file suffix to load.</p>
<div id="d8734701" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>train_loader, valid_loader, test_loader, _, _, _, _ <span class="op">=</span> load_data(<span class="dv">128</span>, <span class="st">"_springs5"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s now examine this data. We get an iterator from the data loader and retrieve the first minibatch. The dataset is in the form of tuples of trajectory information and the ground truth interaction graph.</p>
<div id="456d6bc9" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>(x_sample,rel_sample) <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_sample.shape)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rel_sample.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([128, 5, 49, 4])
torch.Size([128, 20])</code></pre>
</div>
</div>
<p>Let’s look at the interaction graph first. This dataset consists of trajectories of systems of 5 particles. The interaction graph then specifies for each particle whether or not it interacts with every other particle. For 5 particles this gives us 20 interaction pairs.</p>
<div id="364a10e8" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>idx<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rel_sample[idx])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0])</code></pre>
</div>
</div>
<p>This interaction is in the form of a list of interactions pairs. We can convert one such list to an interaction graph adjacency matrix as follows. Here we specify that a particle does not interact with itself by setting the diagonal to 0.</p>
<div id="8bf19fce" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> list_to_adj(rel):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> torch.zeros((<span class="dv">5</span><span class="op">*</span><span class="dv">5</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        b[i<span class="op">*</span><span class="dv">5</span><span class="op">+</span>i<span class="op">+</span><span class="dv">1</span>:(i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span><span class="dv">5</span><span class="op">+</span>(i<span class="op">+</span><span class="dv">1</span>)] <span class="op">=</span> rel[i<span class="op">*</span><span class="dv">5</span>:(i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span><span class="dv">5</span>]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> b.reshape((<span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>b<span class="op">=</span>list_to_adj(rel_sample[idx])</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.reshape((<span class="dv">5</span>,<span class="dv">5</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0., 0., 0., 1.],
        [0., 0., 1., 0., 0.],
        [0., 1., 0., 1., 0.],
        [0., 0., 1., 0., 0.],
        [1., 0., 0., 0., 0.]])</code></pre>
</div>
</div>
<p>We can draw the graph</p>
<div id="7fae7e71" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_graph(b):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    g <span class="op">=</span> b.reshape((<span class="dv">5</span>,<span class="dv">5</span>)).cpu().numpy()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    graph <span class="op">=</span> networkx.from_numpy_array(g)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    networkx.draw(graph, with_labels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>show_graph(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s now examine the trajectory data for the first data point.</p>
<div id="d37ca7e3" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>x_sample[idx].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>torch.Size([5, 49, 4])</code></pre>
</div>
</div>
<p>The shape of the data above specifies that each entry consists of 5 particles with trajectories given for 49 time steps. Furthermore, each state in the trajectory is specified by a 4 dimensional vector. In this case the state is a 2d position and 2d velocity pair specifying the position and velocity of each particle at each time step. We examine the position and velocity of the first particle in the first trajectory for a couple of time steps.</p>
<div id="6f96d6da" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>x_sample[idx,<span class="dv">0</span>,<span class="dv">0</span>:<span class="dv">2</span>,:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([[-0.1272, -0.0987, -0.3305,  0.1197],
        [-0.1380, -0.0945, -0.3275,  0.1196]])</code></pre>
</div>
</div>
<p>Next we define some hyperparameters.</p>
<div id="5727a5a7" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>dims<span class="op">=</span><span class="dv">4</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>num_atoms<span class="op">=</span><span class="dv">5</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>timesteps<span class="op">=</span><span class="dv">49</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>lr<span class="op">=</span><span class="fl">0.0005</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>temp<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>output_var<span class="op">=</span><span class="fl">5e-5</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>_EPS <span class="op">=</span> <span class="fl">1e-10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Recall that we mentioned above that the encoder of the model works on the fully connected graph in order to predict the interaction graph. To pass messages over the fully connected graph, it is useful to define some relational masks specifying which vertices receive messages from which other ones.</p>
<div id="557f2431" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> encode_onehot(labels):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> <span class="bu">set</span>(labels)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    classes_dict <span class="op">=</span> {c: np.identity(<span class="bu">len</span>(classes))[i, :] <span class="cf">for</span> i, c <span class="kw">in</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">enumerate</span>(classes)}</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    labels_onehot <span class="op">=</span> np.array(<span class="bu">list</span>(<span class="bu">map</span>(classes_dict.get, labels)),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                             dtype<span class="op">=</span>np.int32)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> labels_onehot</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>off_diag <span class="op">=</span> np.ones([num_atoms, num_atoms]) <span class="op">-</span> np.eye(num_atoms)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>rel_rec <span class="op">=</span> np.array(encode_onehot(np.where(off_diag)[<span class="dv">0</span>]), dtype<span class="op">=</span>np.float32)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>rel_send <span class="op">=</span> np.array(encode_onehot(np.where(off_diag)[<span class="dv">1</span>]), dtype<span class="op">=</span>np.float32)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>rel_rec <span class="op">=</span> torch.FloatTensor(rel_rec)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>rel_send <span class="op">=</span> torch.FloatTensor(rel_send)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can convert edge features into node features and node features into edge features by passing messages over the fully connected graph using these masks.</p>
<div id="30d57816" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rel_rec.t(), rel_rec.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0.],
        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,
         0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,
         0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
         1., 1.]]) torch.Size([20, 5])</code></pre>
</div>
</div>
<p>For example to convert edge features for the 20 interactions into node features we can multiply the above matrix with the edge feature vector as</p>
<pre><code>torch.matmul(rel_rec.t(), x)</code></pre>
<p>which collects the messages from all neighboring nodes for each vertex and adds the messages.</p>
<p>Next we define a simple MLP class to be used for the nonlinear feature transformations.</p>
<div id="08eb2ce3" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Two-layer fully-connected ELU net with batch norm."""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in, n_hid, n_out, do_prob<span class="op">=</span><span class="fl">0.</span>):</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MLP, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(n_in, n_hid)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(n_hid, n_out)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn <span class="op">=</span> nn.BatchNorm1d(n_out)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout_prob <span class="op">=</span> do_prob</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.init_weights()</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> init_weights(<span class="va">self</span>):</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.modules():</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(m, nn.Linear):</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>                nn.init.xavier_normal(m.weight.data)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>                m.bias.data.fill_(<span class="fl">0.1</span>)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(m, nn.BatchNorm1d):</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>                m.weight.data.fill_(<span class="dv">1</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>                m.bias.data.zero_()</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> batch_norm(<span class="va">self</span>, inputs):</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> inputs.view(inputs.size(<span class="dv">0</span>) <span class="op">*</span> inputs.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.bn(x)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x.view(inputs.size(<span class="dv">0</span>), inputs.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Input shape: [num_sims, num_things, num_features]</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.elu(<span class="va">self</span>.fc1(inputs))</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.dropout(x, <span class="va">self</span>.dropout_prob, training<span class="op">=</span><span class="va">self</span>.training)</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.elu(<span class="va">self</span>.fc2(x))</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.batch_norm(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="encoder" class="level3">
<h3 class="anchored" data-anchor-id="encoder">Encoder</h3>
<p>Next we specify the VAE encoder as a graph neural network. For each particle we construct a single feature vector by using the entire trajectory information. We include three graph neural network layers that convert the node features into edge features into node features and finally into edge features. The final edge features are then used to parameterize the edge probabilities for the graph sampling operation.</p>
<div id="6cc6a854" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLPEncoder(nn.Module):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in, n_hid, n_out<span class="op">=</span><span class="dv">2</span>, do_prob<span class="op">=</span><span class="fl">0.</span>,):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MLPEncoder, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp1 <span class="op">=</span> MLP(n_in, n_hid, n_hid, do_prob)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp2 <span class="op">=</span> MLP(n_hid <span class="op">*</span> <span class="dv">2</span>, n_hid, n_hid, do_prob)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp3 <span class="op">=</span> MLP(n_hid, n_hid, n_hid, do_prob)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp4 <span class="op">=</span> MLP(n_hid <span class="op">*</span> <span class="dv">3</span>, n_hid, n_hid, do_prob)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc_out <span class="op">=</span> nn.Linear(n_hid, n_out)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.init_weights()</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> init_weights(<span class="va">self</span>):</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.modules():</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(m, nn.Linear):</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>                nn.init.xavier_normal(m.weight.data)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>                m.bias.data.fill_(<span class="fl">0.1</span>)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> edge2node(<span class="va">self</span>, x, rel_rec, rel_send):</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Assumes that we have the same graph across all samples.</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        incoming <span class="op">=</span> torch.matmul(rel_rec.t(), x)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> incoming <span class="op">/</span> incoming.size(<span class="dv">1</span>)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> node2edge(<span class="va">self</span>, x, rel_rec, rel_send):</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Assumes that we have the same graph across all samples.</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        receivers <span class="op">=</span> torch.matmul(rel_rec, x)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        senders <span class="op">=</span> torch.matmul(rel_send, x)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        edges <span class="op">=</span> torch.cat([senders, receivers], dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> edges</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs, rel_rec, rel_send):</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Input shape: [num_sims, num_atoms, num_timesteps, num_dims]</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> inputs.view(inputs.size(<span class="dv">0</span>), inputs.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># New shape: [num_sims, num_atoms, num_timesteps*num_dims]</span></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp1(x)  <span class="co"># 2-layer ELU net per node</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.node2edge(x, rel_rec, rel_send)</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp2(x)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>        x_skip <span class="op">=</span> x</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.edge2node(x, rel_rec, rel_send)</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp3(x)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.node2edge(x, rel_rec, rel_send)</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat((x, x_skip), dim<span class="op">=</span><span class="dv">2</span>)  <span class="co"># Skip connection</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp4(x)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.fc_out(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="decoder" class="level3">
<h3 class="anchored" data-anchor-id="decoder">Decoder</h3>
<p>In the decoder we take the initial state and attempt to predict the remaining trajectory. To predict a single time step the function <code>single_step_forward</code> takes as input the current state and the proposed interaction graph. From the states of the nodes as node features we produce edge features by passing messages over all neighbors and then zero out the messages corresponding to edges not present in the proposed graph. The edge messages are then sent to the corresponding nodes after which we apply an MLP to compute the next prediction as a difference with the current state. The process is then repeated for all timesteps.</p>
<div id="f7dafce3" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLPDecoder(nn.Module):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""MLP decoder module."""</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in_node, edge_types, msg_hid, msg_out, n_hid,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                 do_prob<span class="op">=</span><span class="fl">0.</span>):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MLPDecoder, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.msg_fc1 <span class="op">=</span> (nn.Linear(<span class="dv">2</span> <span class="op">*</span> n_in_node, msg_hid))</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.msg_fc2 <span class="op">=</span> (nn.Linear(msg_hid, msg_out))</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.msg_out_shape <span class="op">=</span> msg_out</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_fc1 <span class="op">=</span> nn.Linear(n_in_node <span class="op">+</span> msg_out, n_hid)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_fc2 <span class="op">=</span> nn.Linear(n_hid, n_hid)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_fc3 <span class="op">=</span> nn.Linear(n_hid, n_in_node)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Using learned interaction net decoder.'</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout_prob <span class="op">=</span> do_prob</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> single_step_forward(<span class="va">self</span>, single_timestep_inputs, rel_rec, rel_send,</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>                            single_timestep_rel_type):</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># single_timestep_inputs has shape</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [batch_size, num_timesteps, num_atoms, num_dims]</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># single_timestep_rel_type has shape:</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Node2edge</span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>        receivers <span class="op">=</span> torch.matmul(rel_rec, single_timestep_inputs)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>        senders <span class="op">=</span> torch.matmul(rel_send, single_timestep_inputs)</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        pre_msg <span class="op">=</span> torch.cat([senders, receivers], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> F.relu(<span class="va">self</span>.msg_fc1(pre_msg))</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> F.dropout(msg, p<span class="op">=</span><span class="va">self</span>.dropout_prob)</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> F.relu(<span class="va">self</span>.msg_fc2(msg))</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> msg <span class="op">*</span> single_timestep_rel_type[:, :, :, <span class="dv">1</span>:<span class="dv">2</span>]</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggregate all msgs to receiver</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>        agg_msgs <span class="op">=</span> msg.transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>).matmul(rel_rec).transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>        agg_msgs <span class="op">=</span> agg_msgs.contiguous()</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip connection</span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>        aug_inputs <span class="op">=</span> torch.cat([single_timestep_inputs, agg_msgs], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output MLP</span></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> F.dropout(F.relu(<span class="va">self</span>.out_fc1(aug_inputs)), p<span class="op">=</span><span class="va">self</span>.dropout_prob)</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> F.dropout(F.relu(<span class="va">self</span>.out_fc2(pred)), p<span class="op">=</span><span class="va">self</span>.dropout_prob)</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> <span class="va">self</span>.out_fc3(pred)</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict position/velocity difference</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> single_timestep_inputs <span class="op">+</span> pred</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs, rel_type, rel_rec, rel_send, pred_steps<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Assumes that we have the same graph across all samples.</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> inputs.transpose(<span class="dv">1</span>, <span class="dv">2</span>).contiguous()</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>        sizes <span class="op">=</span> [rel_type.size(<span class="dv">0</span>), inputs.size(<span class="dv">1</span>), rel_type.size(<span class="dv">1</span>),</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>                 rel_type.size(<span class="dv">2</span>)]</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>        rel_type <span class="op">=</span> rel_type.unsqueeze(<span class="dv">1</span>).expand(sizes)</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>        time_steps <span class="op">=</span> inputs.size(<span class="dv">1</span>)</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> (pred_steps <span class="op">&lt;=</span> time_steps)</span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> []</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initial step</span></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>        last_pred <span class="op">=</span> inputs[:, <span class="dv">0</span>:<span class="dv">1</span>, :, :]</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Assumes rel_type is constant (i.e. same across all time steps).</span></span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>        curr_rel_type <span class="op">=</span> rel_type[:, <span class="dv">0</span>:<span class="dv">1</span>, :, :]</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run n prediction steps</span></span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, pred_steps):</span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>            last_pred <span class="op">=</span> <span class="va">self</span>.single_step_forward(last_pred, rel_rec, rel_send,</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>                                                 curr_rel_type)</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>            preds.append(last_pred)</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a>        sizes <span class="op">=</span> [preds[<span class="dv">0</span>].size(<span class="dv">0</span>), preds[<span class="dv">0</span>].size(<span class="dv">1</span>) <span class="op">*</span> pred_steps,</span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>                 preds[<span class="dv">0</span>].size(<span class="dv">2</span>), preds[<span class="dv">0</span>].size(<span class="dv">3</span>)]</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>        <span class="co">#output = Variable(torch.zeros(sizes))</span></span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.zeros(sizes)</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> inputs.is_cuda:</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> output.cuda()</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Re-assemble correct timeline</span></span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(preds)):</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>            output[:, i:i<span class="op">+</span><span class="dv">1</span>, :, :] <span class="op">=</span> preds[i]</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>        pred_all <span class="op">=</span> output[:, :(inputs.size(<span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>), :, :]</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pred_all.transpose(<span class="dv">1</span>, <span class="dv">2</span>).contiguous()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we make a few helper arrays to specify the sending and receiving nodes in a message passing step. These simply correspond to the neighbors in a fully connected graph.</p>
<div id="cddffec2" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate off-diagonal interaction graph</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>off_diag <span class="op">=</span> np.ones([num_atoms, num_atoms]) <span class="op">-</span> np.eye(num_atoms)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>rel_rec <span class="op">=</span> np.array(encode_onehot(np.where(off_diag)[<span class="dv">0</span>]), dtype<span class="op">=</span>np.float32)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>rel_send <span class="op">=</span> np.array(encode_onehot(np.where(off_diag)[<span class="dv">1</span>]), dtype<span class="op">=</span>np.float32)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>rel_rec <span class="op">=</span> torch.FloatTensor(rel_rec)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>rel_send <span class="op">=</span> torch.FloatTensor(rel_send)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a9731964" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#edge weights have dim 2</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> MLPEncoder(timesteps <span class="op">*</span> dims, <span class="dv">256</span>, <span class="dv">2</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>decoder <span class="op">=</span> MLPDecoder(n_in_node<span class="op">=</span>dims,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                         edge_types<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>                         msg_hid<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                         msg_out<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                         n_hid<span class="op">=</span><span class="dv">256</span>, )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using learned interaction net decoder.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/apervez/anaconda3/envs/pytorch1.9_2/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  app.launch_new_instance()</code></pre>
</div>
</div>
<div id="bc787ac3" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>encoder.cuda()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>decoder.cuda()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>rel_rec <span class="op">=</span> rel_rec.cuda()</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>rel_send <span class="op">=</span> rel_send.cuda()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="96e56e62" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(<span class="bu">list</span>(encoder.parameters()) <span class="op">+</span> <span class="bu">list</span>(decoder.parameters()),</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>                       lr<span class="op">=</span>lr)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>train_loader, valid_loader, test_loader, loc_max, loc_min, vel_max, vel_min <span class="op">=</span> load_data(</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">128</span>, <span class="st">"_springs5"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="discrete-sampling" class="level3">
<h3 class="anchored" data-anchor-id="discrete-sampling">Discrete Sampling</h3>
<p>We will sample graphs by selecting a subset of the fully connected graph using the weights output by the encoder by using Gumbel softmax. We define the Gumbel softmax routines below as from the earlier tutorial.</p>
<div id="3c6e4e05" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_softmax(<span class="bu">input</span>, axis<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    trans_input <span class="op">=</span> <span class="bu">input</span>.transpose(axis, <span class="dv">0</span>).contiguous()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    soft_max_1d <span class="op">=</span> F.softmax(trans_input)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> soft_max_1d.transpose(axis, <span class="dv">0</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_gumbel(shape, eps<span class="op">=</span><span class="fl">1e-10</span>):</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> torch.rand(shape).<span class="bu">float</span>()</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span> torch.log(eps <span class="op">-</span> torch.log(U <span class="op">+</span> eps))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gumbel_softmax_sample(logits, tau<span class="op">=</span><span class="dv">1</span>, eps<span class="op">=</span><span class="fl">1e-10</span>):</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    gumbel_noise <span class="op">=</span> sample_gumbel(logits.size(), eps<span class="op">=</span>eps)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> logits.is_cuda:</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>        gumbel_noise <span class="op">=</span> gumbel_noise.cuda()</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> logits <span class="op">+</span> Variable(gumbel_noise)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> my_softmax(y <span class="op">/</span> tau, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gumbel_softmax(logits, tau<span class="op">=</span><span class="dv">1</span>, hard<span class="op">=</span><span class="va">False</span>, eps<span class="op">=</span><span class="fl">1e-10</span>):</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    y_soft <span class="op">=</span> gumbel_softmax_sample(logits, tau<span class="op">=</span>tau, eps<span class="op">=</span>eps)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> hard:</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> logits.size()</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        _, k <span class="op">=</span> y_soft.data.<span class="bu">max</span>(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        y_hard <span class="op">=</span> torch.zeros(<span class="op">*</span>shape)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y_soft.is_cuda:</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>            y_hard <span class="op">=</span> y_hard.cuda()</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        y_hard <span class="op">=</span> y_hard.zero_().scatter_(<span class="op">-</span><span class="dv">1</span>, k.view(shape[:<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> (<span class="dv">1</span>,)), <span class="fl">1.0</span>)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> Variable(y_hard <span class="op">-</span> y_soft.data) <span class="op">+</span> y_soft</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y_soft</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next we define some helper functions for computing accuracies, prediction loss and KL divergence.</p>
<div id="0c6f0ef6" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kl_categorical_uniform(preds, num_atoms, num_edge_types, add_const<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                           eps<span class="op">=</span><span class="fl">1e-16</span>):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    kl_div <span class="op">=</span> preds <span class="op">*</span> torch.log(preds <span class="op">+</span> eps)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> add_const:</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        const <span class="op">=</span> np.log(num_edge_types)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        kl_div <span class="op">+=</span> const</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kl_div.<span class="bu">sum</span>() <span class="op">/</span> (num_atoms <span class="op">*</span> preds.size(<span class="dv">0</span>))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nll_gaussian(preds, target, variance, add_const<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    neg_log_p <span class="op">=</span> ((preds <span class="op">-</span> target) <span class="op">**</span> <span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> variance))</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> add_const:</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>        const <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> np.log(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> variance)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>        neg_log_p <span class="op">+=</span> const</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> neg_log_p.<span class="bu">sum</span>() <span class="op">/</span> (target.size(<span class="dv">0</span>) <span class="op">*</span> target.size(<span class="dv">1</span>))</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> edge_accuracy(preds, target):</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    _, preds <span class="op">=</span> preds.<span class="bu">max</span>(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> preds.<span class="bu">float</span>().data.eq(</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>        target.<span class="bu">float</span>().data.view_as(preds)).cpu().<span class="bu">sum</span>()</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">float</span>(correct) <span class="op">/</span> (target.size(<span class="dv">0</span>) <span class="op">*</span> target.size(<span class="dv">1</span>))</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now train the model. This runs the encoder to get the latent graph parameters and samples the edges using the <code>gumbel_softmax</code> function to get a latent graph which is then passed to the decoder. We use the uniform categorical prior to compute the KL divergence for the VAE loss and a Gaussian likelihood loss with a fixed various for the predictions.</p>
<div id="8bf93b5f" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(epoch, best_val_loss):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> time.time()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    nll_train <span class="op">=</span> []</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    acc_train <span class="op">=</span> []</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    kl_train <span class="op">=</span> []</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    mse_train <span class="op">=</span> []</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    encoder.train()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    decoder.train()</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#scheduler.step()</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, relations) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">#if args.cuda:</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>        data, relations <span class="op">=</span> data.cuda(), relations.cuda()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">#data, relations = Variable(data), Variable(relations)</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> encoder(data, rel_rec, rel_send)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>        edges <span class="op">=</span> gumbel_softmax(logits, tau<span class="op">=</span>temp, hard<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> my_softmax(logits, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> decoder(data, edges, rel_rec, rel_send, timesteps)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>        target <span class="op">=</span> data[:, :, <span class="dv">1</span>:, :]</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>        loss_nll <span class="op">=</span> nll_gaussian(output, target, output_var)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        loss_kl <span class="op">=</span> kl_categorical_uniform(prob, num_atoms, <span class="dv">2</span>)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_nll <span class="op">+</span> loss_kl</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> edge_accuracy(logits, relations)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>        acc_train.append(acc)</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>        mse_train.append(F.mse_loss(output, target).item())</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>        nll_train.append(loss_nll.item())</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>        kl_train.append(loss_kl.item())</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>    nll_val <span class="op">=</span> []</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>    acc_val <span class="op">=</span> []</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>    kl_val <span class="op">=</span> []</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>    mse_val <span class="op">=</span> []</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    encoder.<span class="bu">eval</span>()</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    decoder.<span class="bu">eval</span>()</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, relations) <span class="kw">in</span> <span class="bu">enumerate</span>(valid_loader):</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>        <span class="co">#if args.cuda:</span></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>        data, relations <span class="op">=</span> data.cuda(), relations.cuda()</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> encoder(data, rel_rec, rel_send)</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>        edges <span class="op">=</span> gumbel_softmax(logits, tau<span class="op">=</span>temp, hard<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> my_softmax(logits, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># validation output uses teacher forcing</span></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> decoder(data, edges, rel_rec, rel_send, timesteps)</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>        target <span class="op">=</span> data[:, :, <span class="dv">1</span>:, :]</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>        loss_nll <span class="op">=</span> nll_gaussian(output, target, output_var)</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>        loss_kl <span class="op">=</span> kl_categorical_uniform(prob, num_atoms, <span class="dv">2</span>)</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> edge_accuracy(logits, relations)</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>        acc_val.append(acc)</span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>        mse_val.append(F.mse_loss(output, target).item())</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>        nll_val.append(loss_nll.item())</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>        kl_val.append(loss_kl.item())</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Epoch: </span><span class="sc">{:04d}</span><span class="st">'</span>.<span class="bu">format</span>(epoch),</span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>          <span class="st">'nll_train: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(nll_train)),</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>          <span class="st">'kl_train: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(kl_train)),</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>          <span class="st">'mse_train: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(mse_train)),</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a>          <span class="st">'acc_train: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(acc_train)),</span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a>          <span class="st">'nll_val: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(nll_val)),</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a>          <span class="st">'kl_val: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(kl_val)),</span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>          <span class="st">'mse_val: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(mse_val)),</span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>          <span class="st">'acc_val: </span><span class="sc">{:.10f}</span><span class="st">'</span>.<span class="bu">format</span>(np.mean(acc_val)),</span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>          <span class="st">'time: </span><span class="sc">{:.4f}</span><span class="st">s'</span>.<span class="bu">format</span>(time.time() <span class="op">-</span> t))</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(nll_val)</span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="51fc52f6" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>t_total <span class="op">=</span> time.time()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> np.inf</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>best_epoch <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> train(epoch, best_val_loss)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        best_epoch <span class="op">=</span> epoch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/apervez/anaconda3/envs/pytorch1.9_2/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  This is separate from the ipykernel package so we can avoid doing imports until</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0000 nll_train: 82207.3378531610 kl_train: -0.4316625203 mse_train: 0.0428163237 acc_train: 0.5102473625 nll_val: 13553.7608163568 kl_val: -0.5440562605 mse_val: 0.0070592507 acc_val: 0.5207624604 time: 39.0780s
Epoch: 0001 nll_train: 10482.0866405750 kl_train: -0.8068965521 mse_train: 0.0054594203 acc_train: 0.5672370524 nll_val: 9608.4652764043 kl_val: -0.9848571722 mse_val: 0.0050044091 acc_val: 0.6150959256 time: 38.8682s
Epoch: 0002 nll_train: 7622.5237534467 kl_train: -0.9681852530 mse_train: 0.0039700646 acc_train: 0.6575051950 nll_val: 7999.2846617880 kl_val: -0.9407296845 mse_val: 0.0041662942 acc_val: 0.6889833861 time: 38.9219s
Epoch: 0003 nll_train: 6435.7686271180 kl_train: -0.8848858903 mse_train: 0.0033519629 acc_train: 0.7282261029 nll_val: 6645.1351859177 kl_val: -0.8726646719 mse_val: 0.0034610081 acc_val: 0.7700009889 time: 38.9155s
Epoch: 0004 nll_train: 5131.3655265945 kl_train: -0.7572590768 mse_train: 0.0026725863 acc_train: 0.8130400815 nll_val: 4324.9007367484 kl_val: -0.6718307175 mse_val: 0.0022525526 acc_val: 0.8733831092 time: 38.8255s
Epoch: 0005 nll_train: 3077.5661589874 kl_train: -0.5434278285 mse_train: 0.0016028991 acc_train: 0.8900433584 nll_val: 3308.9670224733 kl_val: -0.4739881709 mse_val: 0.0017234204 acc_val: 0.9016811709 time: 38.8303s
Epoch: 0006 nll_train: 2414.1095929158 kl_train: -0.4157265660 mse_train: 0.0012573488 acc_train: 0.9119279492 nll_val: 2641.4135803995 kl_val: -0.3809240079 mse_val: 0.0013757363 acc_val: 0.9172320016 time: 38.7057s
Epoch: 0007 nll_train: 2069.5431726168 kl_train: -0.3398666841 mse_train: 0.0010778871 acc_train: 0.9245336477 nll_val: 2234.7316940887 kl_val: -0.3186675578 mse_val: 0.0011639228 acc_val: 0.9260087025 time: 38.7296s
Epoch: 0008 nll_train: 1849.1151079339 kl_train: -0.2847137487 mse_train: 0.0009630808 acc_train: 0.9329048114 nll_val: 2150.2909862663 kl_val: -0.2708904545 mse_val: 0.0011199433 acc_val: 0.9309285997 time: 38.5185s
Epoch: 0009 nll_train: 1702.6682693989 kl_train: -0.2453164980 mse_train: 0.0008868064 acc_train: 0.9392786925 nll_val: 1745.5321894778 kl_val: -0.2299301707 mse_val: 0.0009091314 acc_val: 0.9383850870 time: 38.7678s</code></pre>
</div>
</div>
</section>
<section id="visualizing-discovered-graphs" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-discovered-graphs">Visualizing Discovered Graphs</h3>
<p>We can now visualize the actual and predicted interaction graphs for some examples.</p>
<div id="54827039" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>data,relations <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(valid_loader))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>data<span class="op">=</span>data.cuda()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>relations<span class="op">=</span>relations.cuda()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6da19797" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> encoder(data, rel_rec, rel_send)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>_, rel <span class="op">=</span> logits.<span class="bu">max</span>(<span class="op">-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f7ca1310" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rel[<span class="dv">0</span>])</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(relations[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
       device='cuda:0')
tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
       device='cuda:0')</code></pre>
</div>
</div>
<div id="0beaf74c" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    g_act <span class="op">=</span> list_to_adj(relations[i])</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    g_pred <span class="op">=</span> list_to_adj(rel[i])</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Original"</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    show_graph(g_act)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Predicted"</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    show_graph(g_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-12.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-14.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-16.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-18.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="graphs_files/figure-html/cell-30-output-20.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p><a href="https://arxiv.org/abs/1802.04687">Neural Relational Inference for Interacting Systems</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/dslnu\.github\.io\/dl_nlp\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>LNU</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>