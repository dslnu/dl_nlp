---
title: "NLP: Lab 3"
execute:
  enabled: true
  echo: true
  cache: true
format:
  html:
    code-fold: false
jupyter: python3
diagram:
  cache: true
  cache-dir: ./cache
  engine:
    tikz:
      execpath: lualatex
filters:
  - diagram
---

# Lab4: Naive Bayes classifier

## Plan:
1. **Prepare models** for the classifier, based on cleaned-up tokens from Lab3.
2. **Run the Naive Bayes classifier**.

Use `positive_cleaned_tokens_list` and `negative_cleaned_tokens_list` from Lab3

We'll convert these to a data structure usable for NLTK's naive Bayes classifier ([docs here](https://www.nltk.org/_modules/nltk/classify/naivebayes.html)):

```python
[tweet_tokens for tweet_tokens in positive_cleaned_tokens_list][0]
```

```python
def get_token_dict(tokens):
    return dict([token, True] for token in tokens)
    
def get_tweets_for_model(cleaned_tokens_list):   
    return [get_token_dict(tweet_tokens) for tweet_tokens in cleaned_tokens_list]

positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)
negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)
```

Create two datasets for positive and negative tweets. Use 7000/3000 split for train and test data.

```python
import random

positive_dataset = [(tweet_dict, "Positive")
                     for tweet_dict in positive_tokens_for_model]

negative_dataset = [(tweet_dict, "Negative")
                     for tweet_dict in negative_tokens_for_model]

dataset = positive_dataset + negative_dataset

random.shuffle(dataset)

train_data = dataset[:7000]
test_data = dataset[7000:]
```
Finally we use the nltk's NaiveBayesClassifier on the training data we've just created:
```python
from nltk import classify
from nltk import NaiveBayesClassifier
classifier = NaiveBayesClassifier.train(train_data)

print("Accuracy is:", classify.accuracy(classifier, test_data))

print(classifier.show_most_informative_features(10))
```

Note the Positive:Negative ratios.

Let's check some test phrase. First, download punkt sentence tokenizer ([docs here](https://www.nltk.org/api/nltk.tokenize.punkt.html))
```python
nltk.download('punkt_tab')

```
Now we won't rely on `twitter_samples.tokenized`, but rather will use a generic tokenization routine - `word_tokenize`.


```python
from nltk.tokenize import word_tokenize

custom_tweet = "the service was so bad"

custom_tokens = process_tokens(word_tokenize(custom_tweet))

print(classifier.classify(get_token_dict(custom_tokens)))
```
Let's package it as a function and test it:

```python
def get_sentiment(text):
    custom_tokens = process_tokens(word_tokenize(text))
    return classifier.classify(get_token_dict(custom_tokens))

texts = ["bad", "service is bad", "service is really bad", "service is so terrible", "great service", "they stole my money"]
for t in texts:
    print(t, ": ", get_sentiment(t))
```

# Exercises


**Task 0.**  Execute the notebook. 

**Task 1.** Try testing the classifier with different kinds of text - e.g. Reddit comments, tweets, whatever.

**Task 2.** Try to use Logistic [Regression classifier](https://www.nltk.org/_modules/nltk/classify/scikitlearn.html) instead  and compare the results with Naive Bayes.

**Task 3[\*]{style="color:red"}.** Suggest improvements to the code. How can the code be made faster/more accurate?

# Recommended reading 

- Chapter 2.5 from [NLTK book](https://www.nltk.org/book/ch02.html).
- Chapters 4.1, 4.2 from [Jurafsky's book](https://web.stanford.edu/~jurafsky/slp3/). Plus related slides.
