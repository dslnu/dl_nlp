---
title: "NLP: Lab 14 (Translation with Seq2seq and Attention)"
execute:
  enabled: true
  echo: true
  cache: true
format:
  html:
    code-fold: false
jupyter: python3
diagram:
  cache: true
  cache-dir: ./cache
  engine:
    tikz:
      execpath: lualatex
filters:
  - diagram
---

# Description
Please complete notebook and exercises from <https://docs.pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>

## Dataset examples

1. <https://huggingface.co/datasets/toughdata/quora-question-answer-dataset> (`Question â†’ Answer`)
